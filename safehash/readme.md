# ğŸ§© SafeHash  
### Privacy-First Image Fingerprinting to Combat Non-Consensual Image Sharing

SafeHash is a **privacy-preserving prototype** that demonstrates how **image hashing** can be used to detect duplicate uploads of sensitive content **without ever storing the images themselves**.

This project is motivated by the growing problem of **non-consensual image sharing, sextortion, and image-based abuse**, and explores how **hash-sharing systems** could help platforms detect and block re-uploads of harmful content at scale.

> âš ï¸ **Disclaimer:** SafeHash is a student prototype built for learning and demonstration. It does not share data with any platform and is not a production system.

---

## ğŸš¨ Why This Project Exists

Non-consensual image sharing and sextortion are rapidly increasing worldwide.  
Once an image is leaked, it can be re-uploaded repeatedly across platforms, making takedown efforts slow, emotionally damaging, and often ineffective.

A core challenge faced by platforms is:

- How do you **recognise known harmful images**
- **Without storing or redistributing the actual images**
- While respecting **privacy, consent, and legal constraints**

### ğŸ”‘ Core Idea

Instead of sharing images, platforms can share **cryptographic fingerprints (hashes)**.  
If a newly uploaded image matches a known harmful fingerprint, it can be flagged or blocked automatically.

**SafeHash demonstrates the engineering foundation of this idea.**

---

## ğŸ§  What SafeHash Does

SafeHash allows users to:

1. Upload an image through a web interface  
2. Generate **image fingerprints (hashes)**  
3. Store **only the hashes** in a database (no images)  
4. Detect if the **same image is uploaded again**  
5. Browse and export stored hashes for analysis or sharing  

---

## ğŸ” Privacy-First Design

SafeHash is intentionally designed to minimise risk:

- âŒ No raw images are stored long-term  
- âœ… Only fixed-length hash values are persisted  
- âœ… Hashes cannot be reverse-engineered into images  
- âœ… Suitable for conceptual **hash-sharing** across platforms  

This design mirrors real-world trust & safety systems where **privacy is as important as detection**.

---

## âš™ï¸ How It Works (Technical Overview)

### 1ï¸âƒ£ Image Upload
A user uploads an image via the Streamlit web interface.

### 2ï¸âƒ£ Hash Generation
Two different hashes are computed:

#### ğŸ”¹ SHA-256 (Exact Match)
- Cryptographic hash of the raw file bytes  
- Detects **exact duplicates only**  
- Any change (resize, compression) produces a new hash  

#### ğŸ”¹ Perceptual Hash (pHash)
- Captures the **visual structure** of an image  
- Designed to survive resizing or compression  
- Enables future **near-duplicate detection**

### 3ï¸âƒ£ Duplicate Detection
- If the SHA-256 hash already exists â†’ **Exact duplicate detected**
- (Future work) If pHash distance is small â†’ **Visually similar image detected**

### 4ï¸âƒ£ Storage
- Hashes and metadata are stored in **SQLite**
- No image pixels are persisted

---

## ğŸ§ª Current Features

- ğŸ“¤ Image upload interface  
- ğŸ” SHA-256 + perceptual hashing  
- ğŸš« Exact duplicate detection  
- ğŸ—„ï¸ Hash database (â€œHash Vaultâ€)  
- ğŸ” Search and inspect stored hashes  
- ğŸ“ Export hashes as JSON or CSV  
- ğŸ¨ Polished, demo-ready UI  

---

## ğŸ§± Tech Stack

| Component | Technology |
|--------|-----------|
| Frontend | Streamlit |
| Backend | Python |
| Database | SQLite |
| Hashing | SHA-256, pHash |
| Image Processing | Pillow, ImageHash |
| Deployment | Streamlit Community Cloud |

---


---

## ğŸŒ Real-World Significance

Systems inspired by this approach are already used conceptually in:

- Image-based abuse prevention
- Sextortion and child-safety pipelines
- Copyright enforcement
- Platform trust & safety systems

SafeHash demonstrates how **engineering, ethics, and privacy** intersect in modern software design.

---

## ğŸš€ Future Work

This prototype can be extended to include:

- ğŸ” Near-duplicate detection using pHash distance thresholds  
- ğŸ¤ Secure hash-sharing APIs between platforms  
- ğŸ”’ Encryption-at-rest for stored identifiers  
- ğŸ§  ML-based image embeddings for robustness testing  
- ğŸ“Š Precision / recall evaluation of detection accuracy  
- ğŸ—‘ï¸ Auto-expiration and user-controlled deletion  

---

## ğŸ“Œ Important Notes

- This app is for **educational and demonstration purposes only**
- Do **not** upload sensitive personal images to public deployments
- Any real deployment must follow strict legal and ethical guidelines

---

## ğŸ‘¤ Author

**Saksham Garg**  
Mechatronic Engineering â€” University of Sydney  
Portfolio Project (2026)

---

## â­ Demo

A live demo is available via Streamlit Cloud.  
(Database resets on redeploy â€” suitable for demonstrations.)



